{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40% - for two or more filters  \n",
    "\n",
    "20% - for embedded method\n",
    "\n",
    "40% - for wrapper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, data_filename, label_filename):\n",
    "        self.data_filename = data_filename\n",
    "        self.label_filename = label_filename\n",
    "        \n",
    "        self.process_data()\n",
    "        self.X = np.array(self.X)\n",
    "        self.Y = np.array(self.Y)\n",
    "        \n",
    "    \n",
    "    def process_data(self):\n",
    "        self.X = pd.read_csv(self.data_filename, delim_whitespace=True)\n",
    "        self.Y = pd.read_csv(self.label_filename, delim_whitespace=True)\n",
    "        self.X = self.X.dropna(how='any', axis=1)\n",
    "        self.remove_with_one_value()\n",
    "    \n",
    "    def remove_with_one_value(self):\n",
    "        for col in self.X.columns:\n",
    "            if len(self.X[col].unique()) == 1:\n",
    "                self.X.drop(col,inplace=True,axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'Task9_DataSet'\n",
    "filename_data_train = join(data_folder, 'arcene_train.data')\n",
    "filename_label_train = join(data_folder, 'arcene_train.labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataProcessor(filename_data_train, filename_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 9919)\n",
      "[[  0  41  82 ...   0 284 423]\n",
      " [  0   0   1 ...   0  34 508]\n",
      " [  0  56  44 ...   0   0 469]\n",
      " [105   0 141 ...   0   0 354]\n",
      " [ 38  62   0 ...  18  59 340]]\n"
     ]
    }
   ],
   "source": [
    "print(data.X.shape)\n",
    "print(data.X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters:\n",
    "### 1. FRatio Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://stats.stackexchange.com/questions/277123/fisher-score-feature-selection-implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRatioFilter:\n",
    "    def __init__(self, n=10):\n",
    "        self.n = n\n",
    "    \n",
    "    def __calculate_F_ratio__(self,row, y_data):\n",
    "        Mu = np.mean(row)\n",
    "        inter_class = 0.0\n",
    "        intra_class = 0.0\n",
    "        for value in np.unique(y_data):\n",
    "            index_for_this_value = np.where(y_data == value)[0]\n",
    "            n = np.sum(row[index_for_this_value])\n",
    "            mu = np.mean(row[index_for_this_value])\n",
    "            var = np.var(row[index_for_this_value])\n",
    "            inter_class += n * np.power(( mu - Mu),2)\n",
    "            intra_class += (n - 1) * var\n",
    "        \n",
    "        f_ratio = inter_class/intra_class\n",
    "        return f_ratio\n",
    "            \n",
    "    \n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        self.x_data, self.y_data = x_data, y_data\n",
    "        f_ratios = []\n",
    "        for feature in x_data.T:\n",
    "            f_ratio = self.__calculate_F_ratio__(feature, y_data.T)\n",
    "            f_ratios.append(f_ratio)\n",
    "        self.f_ratios = np.array(f_ratios)\n",
    "        # return top n f_ratios\n",
    "        self.selection_indexes = np.argpartition(self.f_ratios, -self.n)[-self.n:]\n",
    "        \n",
    "    def transform(self, x_data, y_data):\n",
    "        return x_data[:,self.selection_indexes]\n",
    "    \n",
    "    def fit_and_transform(self, x_data, y_data):\n",
    "        self.fit(x_data, y_data)\n",
    "        return self.transform(x_data, y_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2193 6165 6155 6163 6162 2201 2202 6157 6156    0]\n"
     ]
    }
   ],
   "source": [
    "fs = FRatioFilter()\n",
    "new_X = fs.fit_and_transform(data.X, data.Y)\n",
    "indexes = fs.selection_indexes\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SpearmanCorrelation Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpearmanRankCorrelationFilter:\n",
    "    def __init__(self,n=10):\n",
    "        self.n = n\n",
    "    \n",
    "    def __calculate_spearmancorrelation__(self,row, y_data):\n",
    "        y_data = np.reshape(y_data, len(y_data[0]))\n",
    "        temp_data = {'row' : row,\n",
    "                     'y_data' : y_data\n",
    "                    }\n",
    "        temp_frame = pd.DataFrame(temp_data)\n",
    "        temp_frame['row_rank'] = temp_frame['row'].rank()\n",
    "        temp_frame['y_data_rank'] = temp_frame['y_data'].rank()\n",
    "        temp_frame['rank_diff_sq'] = (temp_frame['row_rank'] - temp_frame['y_data_rank']).apply(lambda x: np.power(x,2))        \n",
    "        correlation_rho = 1 -  ( 6 * np.sum(temp_frame['rank_diff_sq']) /  ( len(row) * np.power(len(row), 2)  - 1 ) )\n",
    "        return correlation_rho\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        correlations = []\n",
    "        for feature in x_data.T:\n",
    "            correlation = self.__calculate_spearmancorrelation__(feature, y_data.T)\n",
    "            correlations.append(correlation)\n",
    "        self.correlations = np.array(correlations)\n",
    "        self.selection_indexes = np.argpartition(self.correlations, -self.n)[-self.n:]\n",
    "    \n",
    "    def transform(self, x_data, y_data):\n",
    "        return x_data[:,self.selection_indexes]\n",
    "    \n",
    "    def fit_and_transform(self, x_data, y_data):\n",
    "        self.fit(x_data, y_data)\n",
    "        return self.transform(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfc = SpearmanRankCorrelationFilter()\n",
    "sfc.fit(data.X, data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9881 1854 6229 6734 4642 6883 8406 3938 7323 6930]\n"
     ]
    }
   ],
   "source": [
    "new_X = sfc.transform(data.X, data.Y)\n",
    "indexes = sfc.selection_indexes\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SequentialForwardSelection:\n",
    "    def __init__(self, model, n=10):\n",
    "        self.n = n\n",
    "        self.model = model\n",
    "        self.selection_indexes = []\n",
    "    \n",
    "    \n",
    "    def __calculate_accuracy__(self, predicted, actual ):\n",
    "        correct = 0.0\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == actual[i]:\n",
    "                correct += 1\n",
    "        \n",
    "        return correct/ len(predicted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __fit_model__(self, dataset, y_data):\n",
    "        self.model.fit(dataset, y_data)\n",
    "        predicted_y = self.model.predict(dataset)\n",
    "        accuracy = self.__calculate_accuracy__(predicted_y, y_data)\n",
    "        return accuracy\n",
    "        \n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        number_of_selected_feature = 0\n",
    "        selected_dataset = []\n",
    "        best_accuracy = 0\n",
    "        self.accuracy = []\n",
    "        for i, feature in enumerate(x_data.T):\n",
    "            temp_dataset = [column for column in selected_dataset]\n",
    "            temp_dataset.append(feature)\n",
    "            \n",
    "            current_accuracy = self.__fit_model__(np.array(temp_dataset).T, y_data)\n",
    "            self.accuracy.append(current_accuracy)\n",
    "            if current_accuracy > best_accuracy:\n",
    "                number_of_selected_feature += 1\n",
    "                best_accuracy = current_accuracy\n",
    "                selected_dataset = temp_dataset\n",
    "                self.selection_indexes.append(i)\n",
    "                if number_of_selected_feature >= self.n:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "    def transform(self, x_data, y_data):\n",
    "        return x_data[:,np.array(self.selection_indexes)]\n",
    "\n",
    "    \n",
    "    def fit_and_transform(self, x_data, y_data):\n",
    "        self.fit(x_data, y_data)\n",
    "        return self.transform(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Wrapper On Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SequentialForwardSelection(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.fit(data.X, data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 4, 7, 19, 33, 44, 61, 63]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.selection_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = sfs.transform(data.X, data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5656565656565656, 0.5656565656565656, 0.5757575757575758, 0.5959595959595959, 0.7373737373737373, 0.7171717171717171, 0.7373737373737373, 0.7676767676767676, 0.7070707070707071, 0.7272727272727273, 0.7373737373737373, 0.7676767676767676, 0.7474747474747475, 0.7373737373737373, 0.696969696969697, 0.7171717171717171, 0.7474747474747475, 0.7676767676767676, 0.7272727272727273, 0.7777777777777778, 0.7474747474747475, 0.7272727272727273, 0.7575757575757576, 0.7272727272727273, 0.6868686868686869, 0.7575757575757576, 0.7474747474747475, 0.7676767676767676, 0.7373737373737373, 0.7373737373737373, 0.7575757575757576, 0.7777777777777778, 0.7676767676767676, 0.797979797979798, 0.7878787878787878, 0.7777777777777778, 0.7777777777777778, 0.7777777777777778, 0.7878787878787878, 0.7777777777777778, 0.7777777777777778, 0.797979797979798, 0.7777777777777778, 0.7777777777777778, 0.8080808080808081, 0.7878787878787878, 0.7777777777777778, 0.7777777777777778, 0.797979797979798, 0.797979797979798, 0.797979797979798, 0.797979797979798, 0.7777777777777778, 0.7676767676767676, 0.7575757575757576, 0.8080808080808081, 0.7676767676767676, 0.8080808080808081, 0.797979797979798, 0.7777777777777778, 0.797979797979798, 0.8181818181818182, 0.797979797979798, 0.8383838383838383]\n"
     ]
    }
   ],
   "source": [
    "print(sfs.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
